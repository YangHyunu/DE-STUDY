### BFR 알고리즘 (Bradley-Fayyad-Reina Algorithm)

BFR 알고리즘은 대규모 데이터 세트를 클러스터링하기 위해 설계된 알고리즘으로, K-means 알고리즘을 확장한 형태입니다. 주로 대규모 데이터 세트를 처리하는 데 사용되며, 데이터가 메모리에 모두 적재되지 않는 경우에도 효과적으로 작동합니다.

## Three Classes of Points

데이터 포인트들을 읽어와서 3가지 집합으로 분류한다.

1. **Discard set (DS)**:
   - 할당된 점(포인트)들이 센트로이드에 충분히 가까운 경우.
   - 이 점들을 이용해 정보를 업데이트한 후 점들을 버린다.

2. **Compressed set (CS)**:
   - 현재 센트로이드에 가깝지는 않지만 할당된 점 끼리는 작은 클러스터를 만들 수 있을 정도로 가까운 경우.
   - 이 점들을 이용해 정보를 업데이트한 후 점들을 버린다.

3. **Retained set (RS)**:
   - 센트로이드와 가깝지도 않고 서로 충분히 가까워 작은 클러스터를 만들 수 없는 점들.
   - 큰 메모리를 잡아먹지 않기 때문에 유지함.

![alt text](image-43.png)

각 클러스터에 대해, Discard set (DS)와 Compressed set (CS)는 다음과 같이 요약된다:
- \( N \): 점의 수
- 길이 \( d \)의 벡터 \( \text{SUM} \) (d는 차원의 수): 각 차원에서 모든 점의 성분 합
  - \( \text{SUM}_i \): 벡터 SUM의 i번째 차원의 좌표 합
- 길이 \( d \)의 벡터 \( \text{SUMSQ} \): 각 차원에서 모든 점의 성분 제곱 합
  - \( \text{SUMSQ}_i \): 벡터 SUMSQ의 i번째 차원의 좌표 제곱 합

목표: 점 집합을 (1) 점의 수, (2) 중심점(centroid), (3) 각 차원의 표준 편차(STDEV)로 표현한다.
- \( 2d + 1 \) 값이 이러한 통계를 제공한다 (d = 차원의 수).
- \( N \): 점의 수.

- 각 차원의 `평균` = \( \frac{\text{SUM}_i}{N} \) (centroid)
  - 즉, 센트로이드를 계산할 필요 없이 \( \frac{\text{SUM}_i}{N} \)으로 얻을 수 있다.
  - \( \text{SUM}_i \): SUM의 i번째 성분.
- 클러스터의 discard set의 i번째 차원의 `분산` = \( \frac{\text{SUMSQ}_i}{N} - \left( \frac{\text{SUM}_i}{N} \right)^2 \)
  - 참고: \( \text{Var}(X) = \mathbb{E}[(X - \mathbb{E}[X])^2] = \mathbb{E}[X^2] - (\mathbb{E}[X])^2 \)
  - 분산의 제곱근 = 표준 편차(STDEV).

Q: 왜 중심점과 표준 편차를 직접 저장하는 대신 이 표현을 사용하는가?
    -> 각 점이 할당될 때마다 센트로이드와 분산을 계산하지 않기 위해서, 즉 오버헤드를 방지하기 위해.

## Processing the “Memory-Load” of Points (1)

1. 클러스터 중심에 "충분히 가까운" 점들을 찾아 해당 클러스터와 DS에 추가한 후, 이 점들을 버린다.
   - 새로운 점들을 반영하여 클러스터의 통계량을 조정한다: \( N_s \), \( \text{SUM}_s \), \( \text{SUMSQ}_s \)

2. 어떤 중심에도 충분히 가깝지 않은 점들에 대해서는, 메인 메모리 클러스터링 알고리즘을 사용하여 남은 점들과 기존 RS를 클러스터링한다.
   - 클러스터를 요약하여 CS에 추가한다.
   - 외곽 점들(즉, 단일 클러스터)은 RS가 된다.

## Processing the “Memory-Load” of Points (2)

3. 새로운 미니 클러스터들을 기존 CS와 서로 병합하는 것을 고려한다.

4. 클러스터나 미니 클러스터에 할당된 점들(즉, RS에 속하지 않은 점들)은 보조 메모리에 기록한다.

5. 만약 이것이 마지막 입력 데이터 청크라면, CS와 RS에 대해 다음과 같은 처리를 해야 한다.
   - 이들을 이상치로 간주하여 전혀 클러스터링하지 않는다.
   - RS의 각 점을 가장 가까운 중심 클러스터에 할당한다.
   - 각 미니 클러스터를 가장 가까운 중심 클러스터와 결합한다.

## 고려해야 할 부분

### Q1) 점이 클러스터에 "충분히 가까운지"를 어떻게 결정하는가?
- 점과 클러스터 중심 간의 거리(예: 유클리드 거리 혹은 측도)가 미리 정의된 `임계값` 이하인 경우, 점을 해당 클러스터에 추가한다.

### Q2) 두 개의 압축 집합(CS, 미니 클러스터)을 하나로 결합할 가치가 있는지 어떻게 결정하는가?
- 두 압축 집합의 중심 간의 거리와 각 집합의 분산을 고려하여, 미리 정의된 임계값 이하인 경우 두 집합을 결합한다.

### Q1) 새로운 점을 클러스터에 넣고 버릴지 결정하는 방법이 필요하다.
- `BFR`은 두 가지 방법을 제안한다:
  - 현재 가장 가까운 중심에 속할 가능성이 높은 경우.
  - `마할라노비스` 거리가 임계값보다 작은 경우.