# What is Hadoop?

1. 오픈 소스 데이터 저장 및 처리 프레임워크
2. 대규모 확장 가능하고 자동으로 병렬 처리할 수 있음
- Based on work from Google
- GFS + MapReduce + BigTable
- Current Distributions based on Open Source and Vendor Work

### **RDBMS vs. Hadoop**

| **Category** | **Traditional RDBMS** | **Hadoop / MapReduce** |
| --- | --- | --- |
| **Data Size** | Gigabytes (Terabytes) | Petabytes (Hexabytes) |
| **Access** | Interactive and Batch | Batch – NOT Interactive |
| **Updates** | Read / Write many times | Write once, Read many times |
| **Structure** | Static Schema | Dynamic Schema |
| **Integrity<무결성>** | High (ACID) | Low |
| **Scaling<확장성>** | Nonlinear | Linear |
| **Query Response Time** | Can be near immediate | Has latency (due to batch processing) |

- **ACID**: Atomicity, Consistency, Isolation, Durability

## Why Use Hadoop?

- 싸다
    - 매우 저렴한 비용으로 대규모로 확장가능하다
- 빠르다
    - 데이터 처리를 병렬처리하므로
- 특정한 타입의 빅데이터 처리에 특히 최적화 되어있다.

## Hadoop Ecosystem Tools

#### HDFS (Hadoop Distributed File System):

- 현재까지 사용되는 분산 파일 시스템으로, 대규모 데이터를 여러 노드에 분산 저장.
- 클라우드 스토리지와의 통합이나 대안으로 Amazon S3 등 클라우드 기반 스토리지와도 많이 사용됨.

#### YARN (Yet Another Resource Negotiator):
- 자원 관리의 핵심으로 사용되며, Spark, Flink, Kafka 등 다양한 처리 엔진과 함께 자원 관리 및 클러스터 운영을 돕는 역할을 함.

#### Apache Spark:
- MapReduce를 대체하거나 보완하는 **인메모리(in-memory)** 데이터 처리 엔진으로, 실시간 스트리밍과 배치 처리 모두 지원.
- Hadoop 생태계에서 `가장 많이 사용`하는 데이터 처리 엔진 중 하나로 빠른 속도가 장점.

#### Apache Kafka:
- **실시간 스트리밍**과 `메시지 큐` 역할을 하는 도구로, 분산 스트리밍 플랫폼.
실시간 데이터 처리나 데이터 파이프라인 구성 시 필수적.

#### Apache Flink:
- `실시간 스트림 처리`에 최적화된 엔진으로, 배치 및 스트리밍 작업 모두 지원.
Spark보다 빠른 처리 성능을 제공하며, 실시간 분석에 자주 사용됨.

#### Hive (with LLAP):
- Hive는 SQL 기반의 대용량 데이터 쿼리 엔진으로 사용되며, **LLAP(Live Long and Process)**으로 실시간 성능을 향상시킴.
빅데이터를 SQL로 처리하기 위한 프레임워크.

#### HBase:
- 대규모 **NoSQL** 분산 데이터베이스로, 실시간 데이터 저장 및 읽기/쓰기 작업에 강점을 가짐.
Apache Phoenix와 통합하여 SQL 쿼리도 지원.

#### Presto:
- 대규모 데이터 분석을 위한 분산 SQL 쿼리 엔진으로, Hive보다 더 빠르고 가벼운 SQL 처리 엔진으로 많이 사용됨.
Hadoop 외에도 다양한 데이터 소스에 대해 쿼리를 수행할 수 있음.
#### Airflow:
- 워크플로우 관리와 스케줄링 도구로, 복잡한 데이터 파이프라인을 관리하고 자동화.
특히 데이터 엔지니어링에서 널리 사용됨.

#### Delta Lake (with Apache Spark):
- ACID 트랜잭션을 지원하는 레이크하우스(lakehouse) 아키텍처로, 데이터 레이크에서 데이터 무결성을 보장.
Spark와 결합하여 스트리밍 데이터 처리와 데이터 레이크 저장을 효율적으로 처리.


# Hadoop: Apache 프레임워크 세트의 일부, 그 이상
## 전체 스택 구조
Hadoop의 현대적인 스택은 다음과 같은 계층적 구조로 이루어져 있다:

- **Hadoop Core - HDFS & Cloud Storage**: HDFS, Amazon S3, Google Cloud Storage 등을 사용하여 데이터를 분산 저장하고 관리한다.
  
- **Data Access**: Hive, Presto, HBase, Apache Drill 등을 사용하여 대규모 데이터를 쿼리하고 관리한다.

- **Processing Engines**: Apache Spark, Apache Flink, MapReduce는 데이터를 병렬 처리하고, 실시간 또는 배치 데이터를 효율적으로 처리한다.

- **Tools & Libraries**: Apache Kafka, Airflow, Flume, Sqoop과 같은 도구는 데이터를 수집하고 파이프라인을 관리하며, 실시간 또는 배치로 처리할 수 있게 돕는다.
  
- **Monitoring & Alerting**: Cloudera Manager, Ambari, Prometheus와 같은 도구를 사용하여 클러스터 상태를 실시간 모니터링하고 경고 시스템을 통해 문제를 감지한다.
  

### Core parts of Hadoop distribution:

| **Category**                | **Components**                                                                 |
|-----------------------------|-------------------------------------------------------------------------------|
| **HDFS & Cloud Storage**    | HDFS, Amazon S3, Google Cloud Storage                                         |
| **Data Processing Engines** | Apache Spark, Apache Flink, MapReduce                                         |
| **Data Access Frameworks**  | Hive, Presto, HBase                                                           |
| **Data Collection & ETL**   | Apache Kafka, Apache Flume, Sqoop                                             |
| **Monitoring & Management** | Cloudera Manager, Ambari, Prometheus                                          |

![alt text](image-9.png)


![alt text](image-10.png)

## Hadoop MR components

### Master: **JobTracker**

- **역할**: 클러스터에서 MapReduce 작업을 관리하는 마스터 노드 역할을 수행.
    - **MapReduce 작업 제어**: 클러스터에서 실행되는 모든 MapReduce 작업을 관리하는 역할을 함.
    - **작업 할당**: 클러스터의 다른 노드에 있는 **TaskTracker**에 Map 및 Reduce 작업을 할당.
    - **작업 모니터링**: 작업이 실행되는 동안 이를 모니터링하고, 진행 상황을 추적.
    - **실패한 작업 재시작**: 클러스터 내에서 실패한 작업을 다른 노드에서 다시 실행하도록 함.

### Slave: **TaskTracker**

- **역할**: 각 슬레이브 노드에서 개별적으로 MapReduce 작업을 실행하고 JobTracker와 통신.
    - **단일 TaskTracker**: 슬레이브 노드당 하나의 TaskTracker가 할당 됨.
    - **작업 실행 관리**: 각 노드에서 개별 작업을 실행하고 관리.
    - **병렬 처리 지원**: 여러 JVM을 인스턴스화하여 병렬로 작업을 처리할 수 있음.
    - **JobTracker와의 통신**: **Heartbeat**를 통해 JobTracker와 통신하여 상태를 보고하며 태스크를 판단함.
  
![alt text](image-11.png)

1 →V2 job_tracker 가 **리소스 관리**(클러스터 자원의 할당)와 **작업 관리**(MapReduce 작업을 트래킹, Task 할당, 상태 관리)를 모두 맡아 동시에 처리 하던 것을 두 개의 컴포넌트로 분리시킴

- NameNode →NameNode,Secondary NameNode
- DataNode → DataNode
- JobTracker → ResourceManager, ApplicationManager
- TaskTracker → NodeManager

### **Hadoop V1 → V2 구조 변경: JobTracker 분리**

### **1. Hadoop V1에서의 JobTracker**:

- **JobTracker**는 **리소스 관리**와 **작업 관리**를 **모두** 담당했다.
- **문제점**:
    - **리소스 관리**: 클러스터 내 **전체 자원**(CPU, 메모리 등)을 관리하고 각 작업에 자원을 할당하는 역할.
    - **작업 관리**: **MapReduce 작업을 트래킹**하고 **작업(Task)**을 각 노드에 할당하며, 작업의 상태를 관리.
    - **JobTracker**가 리소스와 작업 모두를 관리하다 보니 큰 클러스터에서 **부하가 증가**했고, 이로 인해 **확장성**이 제한되었음.
    - 또한, **단일 장애 지점(Single Point of Failure)**이 되어, JobTracker에 문제가 생기면 **전체 클러스터가 중단**될 위험이 있었음.

### **2. Hadoop V2(YARN)에서의 변화**:

- **JobTracker**의 역할이 **두 개의 컴포넌트**로 **분리**되었다:
- **분리의 장점**:
    - **ResourceManager**:
        - **클러스터 전체 자원의 관리**를 담당.
        - CPU, 메모리 등의 자원을 추적하고, 각 작업이 사용할 자원을 할당.
    - **ApplicationMaster**:
        - 각 **작업(Job 또는 Application)**에 대해 **개별적으로 생성**되어, 해당 작업의 **실행을 관리**합니다.
        - **작업 흐름 관리**(예: Map → Reduce 작업 순서 조정, 오류 처리)와 **작업의 상태를 추적**하는 역할.
    - **리소스 관리와 작업 관리가 분리**됨으로써 확장성이 향상되었음.
    - **ResourceManager**는 **중앙 집중식 리소스 관리자**로, **ApplicationMaster**는 개별 작업을 관리하는 방식으로 운영됨.
    - **MRAppMaster**는 **MapReduce 작업**을 위한 ApplicationMaster의 예시이며, 각 MapReduce 작업에 대해 생성되어 해당 작업을 관리함.

---

### **3. YARN에서의 NodeManager와 역할 관계**:

- **NodeManager**:
    - **각 노드에서 실행되는 작업을 관리**하고, **자원 사용 상태를 모니터링**.
    - ResourceManager로부터 **컨테이너(Container)**를 할당받아 작업을 실행하고, 작업 상태를 ApplicationMaster에게 보고.
- **ApplicationMaster**:
    - *각 작업(Job)**에 대해 하나씩 생성되며, 해당 작업의 **실행 관리**와 **상태 추적**을 담당.
    - **NodeManager**와 상호작용하여 **작업을 실행**하고, 작업의 진행 상황을 ResourceManager에 보고.
- **ResourceManager**:
    - *클러스터 전체 자원(CPU, 메모리 등)**을 관리하며, **자원을 할당**하는 중앙 관리자 역할.
    - 각 ApplicationMaster의 자원 요청을 수락하고, 적절한 노드(NodeManager)에 자원을 할당.

### 예시

- **10개의 CPU 코어**가 있는 노드에서 **10개의 Map 작업**이 동시에 실행되는 경우:
    - **YARN**의 **ResourceManager**는 **10개의 작업**에 필요한 **자원을 할당시킴**.
    - **NodeManager**는 **10개의 컨테이너**를 생성하여 각 작업이 **1개의 CPU 코어**와 메모리를 사용하도록 설정함.
    - 이때 **MRAppMaster**는 작업의 진행 상태를 모니터링하며, 각 작업이 정상적으로 완료되는지 확인함.
- **병목 현상 완화**: 만약 **느린 작업**이 있다면, **YARN**은 이를 감지하고 **speculative execution**(추측 실행)을 통해 **동일한 작업을 다른 노드에서 병렬로 실행**하여 작업 속도를 향상시킴.
![alt text](image-12.png)